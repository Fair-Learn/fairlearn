{% extends 'base.html' %}

{% block content %}

<img src="{{ url_for('static', filename='images/fairlearn.png') }}" alt="Fairlearn Logo" class="logo mb-4" width="200">

<p>Developed by ITU, Fairlearn is an open-source toolkit designed to examine, report, and mitigate discrimination and bias in machine learning models. It leverages leading fairness tools, including AIF360, Themis-ML, and Aequitas, to perform comprehensive bias audits and fairness assessments. Fairlearn enables developers, analysts, and policymakers to make informed decisions by providing performance comparisons and mitigation strategies, ensuring equitable and unbiased AI applications. We invite you to use and contribute to the improvement of Fairlearn.</p>

<h1>What is Fairness?</h1>
<p>Fairness in machine learning refers to the practice of ensuring that models make unbiased decisions, providing equal outcomes for different groups of people. This means avoiding discrimination based on attributes such as race, gender, age, or any other protected characteristics.</p>

<h2>How Does Fairness Work?</h2>
<p>Fairness in machine learning is achieved by identifying and mitigating biases in the data, the models, and the predictions. This involves:</p>
<ul>
    <li>Detecting biases in the training data</li>
    <li>Using algorithms that can reduce or eliminate these biases</li>
    <li>Evaluating the models using fairness metrics to ensure equitable outcomes</li>
</ul>

<h2>Fairness Tools</h2>
<p>To help achieve fairness, several tools and techniques have been developed:</p>


    <div class="container my-5">
        <div class="row">
            <div class="col-md-3">
                <div class="box p-4 text-center">
                    <img src="{{ url_for('static', filename='images/aif360.png') }}" alt="Fairlearn Logo" class="logo mb-4">
                    <p class="description">A toolkit for measuring and mitigating bias in machine learning models, providing algorithms for fairness pre-processing, in-processing, and post-processing.</p>
                    <a href="/aif360" class="btn btn-primary mt-3">Go to Project Page</a>
                </div>
            </div>
            <div class="col-md-3">
                <div class="box p-4 text-center">
                    <img src="{{ url_for('static', filename='images/themis.png') }}" alt="Themis Logo" class="logo mb-4">
                    <p class="description">A library focused on bias detection and mitigation in machine learning models, offering tools to identify and correct biases.</p>
                    <a href="/themis" class="btn btn-primary mt-3">Go to Project Page</a>
                </div>
            </div>
            <div class="col-md-3">
                <div class="box p-4 text-center">
                    <img src="{{ url_for('static', filename='images/aequitas.png') }}" alt="Aequitas Logo" class="logo mb-4">
                    <p class="description">A tool for identifying and analyzing bias and fairness in decision-making processes, helping to ensure equitable outcomes across groups.</p>
                    <a href="/aequitas" class="btn btn-primary mt-3">Go to Project Page</a>
                </div>
            </div>
            <div class="col-md-3">
                <div class="box p-4 text-center">
                    <img src="{{ url_for('static', filename='images/rsfair.png') }}" alt="RS Fair Logo" class="logo mb-4">
                    <p class="description">A tool that uses representative sampling to evaluate and improve the fairness performance of machine learning models by detecting and correcting discriminatory inputs.</p>
                    <a href="/rsfair" class="btn btn-primary mt-3">Go to Project Page</a>
                </div>
            </div>
        </div>
    </div>


<h3>Datasets Implemented</h3>

<p>We have provided three sample datasets to explore bias checking and mitigation:</p>


<div class="container my-5">
        <div class="info-box">
            <img src="{{ url_for('static', filename='images/check_green.png') }}" alt="Tick" width="30">
            <div>
                <p class="title">German Credit</p>
                <p>This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix. <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">Detail</a></p>
            </div>
        </div>
        <div class="info-box">
            <img src="{{ url_for('static', filename='images/check_gray.png') }}" alt="Tick" width="30">
            <div>
                <p class="title soon">Adult Census - To be soon</p>
                <p>Predict whether income exceeds $50K/yr based on census data. Also known as "Census Income" dataset. <a href="https://archive.ics.uci.edu/ml/datasets/adult">Detail</a></p>
            </div>
        </div>
        <div class="info-box">
            <img src="{{ url_for('static', filename='images/check_gray.png') }}" alt="Tick" width="30">
            <div>
                <p class="title soon">Taiwan Credit Default - To be soon</p>
                <p>This research aimed at the case of customers' default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. <a href="https://archive.ics.uci.edu/ml/datasets/Taiwan+Credit+Default">Detail</a></p>
            </div>
        </div>
    </div>

<h3>Fairness Methods Implemented</h3>
<p>We have implemented various fairness methods, including:</p>
<ul>
    <li> <b>Pre-processing:</b> <br>Adjusts data before model training to reduce bias by ensuring fair representation of protected attributes.</li>
<div class="container my-5">
        <div class="row">
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Label Flipping (Aequitas)</p>
                        <p>Adjusts the labels in the dataset to balance class distributions.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Prevalence Sampling (Aequitas)</p>
                        <p>Changes the sampling strategy to address class imbalance.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Data Repairer (Aequitas)</p>
                        <p>Modifies the data to reduce bias without significantly altering its distribution.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Representative Sampling (RSFair)</p>
                        <p>Creating a subset of data that accurately mirrors the original dataset's key characteristics.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Disparate Impact Remover (AIF360)</p>
                        <p>Transforms the data to remove disparate impact.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Reweighing (AIF360)</p>
                        <p>Adjusts the weights of the instances to ensure fairness.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_green.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title">Relabeller (Themis-ML)</p>
                        <p>Reassigns labels to correct biases in the data.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_gray.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title soon">Optimized Preprocessing (AIF360) - To be soon</p>
                        <p>Reassigns labels to correct biases in the data.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_gray.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title soon">Correlation Suppression (Aequitas) - To be soon</p>
                        <p>Removes features that are highly correlated with the sensitive attribute.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_gray.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title soon">Massaging (Aequitas) - To be soon</p>
                        <p>Flips selected labels to reduce prevalence disparity between groups.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_gray.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title soon">Feature Importance Suppression (Aequitas) - To be soon</p>
                        <p>Iterively removes the most important features with respect to the sensitive attribute.</p>
                    </div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="method-box">
                    <img src="{{ url_for('static', filename='images/check_method_gray.png') }}" alt="Tick" width="30">
                    <div>
                        <p class="title soon">Learning Fair Representations (AIF360) - To be soon</p>
                        <p>Transforms data into a space where protected and unprotected groups have similar distributions.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
   
    <li style="color: #999;"> <b>In-processing - To be soon:</b> <br>Modifies learning algorithms to incorporate fairness constraints directly during the model training process.</li>

    <li style="color: #999;"> <b>Post-processing - To be soon:</b> <br>Alters model predictions to improve fairness without changing the underlying model or training data.</li>
</ul>

<h3>Models Implemented</h3>
<p>To explore the impact of fairness methods on model performance, we have implemented four different machine learning models:</p>

<div class="container">
        <div class="model-container">
            <div class="model-box">
                <div class="model-header">Logistic Regression</div>
                <div class="model-description">Uses a logistic function to predict binary outcomes.</div>
            </div>
            <div class="model-box">
                <div class="model-header">Random Forest</div>
                <div class="model-description">Constructs an ensemble of decision trees to improve accuracy and reduce overfitting.</div>
            </div>
            <div class="model-box">
                <div class="model-header">Support Vector Machine</div>
                <div class="model-description">Finds the optimal hyperplane that maximizes the margin between different classes.</div>
            </div>
            <div class="model-box">
                <div class="model-header">Gradient Boosting Machines</div>
                <div class="model-description">Builds models sequentially to correct the errors made by previous models.</div>
            </div>
        </div>
    </div>

<h2>Flow Chart</h2>
<p>Fairlearn's architecture is designed to be modular and extensible, integrating multiple fairness tools for comprehensive bias assessment and mitigation.</p>

<img src="{{ url_for('static', filename='images/flow_chart.png') }}" alt="Flow Chart" width="1300">

<h2>Evaluation Criteria</h2>
<p>To evaluate the fairness and performance of the models, we use the following metrics:</p>

<div class="container my-5">
    <div class="row">
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Balanced Accuracy</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Balanced Accuracy is a metric that accounts for class imbalance by taking the average of recall (sensitivity) obtained on each class.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">(1/2) * ((TP / (TP + FN)) + (TN / (TN + FP)))</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Theil Index</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Theil Index is an economic measure of inequality that can be applied to predictions in machine learning to measure the disparity in predictive performance across different groups.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">(1/N) * Σ ( (pi / p̄) * ln(pi / p̄) )</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Average Odds Difference</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Average Odds Difference measures the difference in both true positive rates (TPR) and false positive rates (FPR) between the privileged and unprivileged groups.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">((TPR_unprivileged - TPR_privileged) + (FPR_unprivileged - FPR_privileged)) / 2</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Equal Opportunity Difference</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Equal Opportunity Difference measures the difference in true positive rates (TPR) between the privileged and unprivileged groups.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">TPR_unprivileged - TPR_privileged</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Statistical Parity Difference</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Statistical Parity Difference measures the difference in positive outcome rates between the privileged and unprivileged groups.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">P(Y^ = 1 | D = unprivileged) - P(Y^ = 1 | D = privileged)</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Disparate Impact</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>Disparate Impact measures the ratio of positive outcome rates between the privileged and unprivileged groups.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">P(Y^ = 1 | D = unprivileged) / P(Y^ = 1 | D = privileged)</p>
                </div>
            </div>
        </div>
        <div class="col-md-6">
            <div class="evaluation-card">
                <div class="evaluation-header">Equal Opportunity Difference</div>
                <div class="evaluation-body">
                    <p class="evaluation-definition">Definition:</p>
                    <p>The Area Under the Receiver Operating Characteristic Curve (AUC-ROC) measures the model's ability to distinguish between positive and negative classes.</p>
                    <div class="evaluation-divider"></div>
                    <p class="evaluation-formula">Formula:</p>
                    <p class="evaluation-formula-text">∫(TPR(FPR)) d(FPR) from 0 to 1</p>
                </div>
            </div>
        </div>
        
    </div>
</div>


<div class="buttons">
    <a class="button" href="https://github.com/Fair-Learn/fairlearn">Go to project page</a>
</div>

<a class="btn btn-primary mt-3"" href="{{ url_for('demo') }}">Start Demo</a>

<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.9.3/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>

{% endblock %}
